{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all required libraries\n",
    "You need to have CUDA support and pycuda installed. \n",
    "Also install OpenCV version: 3.4.2.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import time\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN CPU Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KNN Implementation \n",
    "\"\"\"\n",
    "\n",
    "def euclidianDistance(des1, des2):\n",
    "    distance = 0\n",
    "    \n",
    "    for x in range(len(des1)):\n",
    "        distance += pow(des1[x] - des2[x], 2)\n",
    "        \n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "def EUBetter(des1,des2,distances,iteration):\n",
    "    des1 = np.array(des1)\n",
    "    des2 = np.array(des2)\n",
    "    \n",
    "    distance = des1 - des2\n",
    "    distance = np.power(distance,2)\n",
    "    distance = np.sum(distance, axis = 1)\n",
    "    distance = np.sqrt(distance)\n",
    "    distance_indices = np.argsort(distance)\n",
    "    \n",
    "    k_match = []\n",
    "    for i in range(2):\n",
    "        k_match.append(cv2.DMatch(iteration,distance_indices[i],distance[distance_indices[i]]))\n",
    "    return k_match\n",
    "    \n",
    "def KNNMatch(des1,des2, k = 2): #query , #train\n",
    "    matches = []\n",
    "    for i in range(len(des1)):\n",
    "        distances = []\n",
    "        \n",
    "        t1 = time.time()\n",
    "        k_match = EUBetter(des1[i], des2, distances,i)\n",
    "        matches.append(k_match) \n",
    "                               \n",
    "    return matches\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main class of Structure of Motion Solver\n",
    "This class has methods to load Images, Detect and match features. computing essential matrix, triangulating points and writing object finals. The object file can be visualzied in Meshlab. The run method will execute the SFM pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SFMSolver(object):\n",
    "\n",
    "    def __init__(self, img_pattern, intrinsic, output_dir, downscale=1):\n",
    "        \"\"\"\n",
    "        img_pattern: regex pattern used by glob to read the files\n",
    "        instrinsic:\n",
    "        \"\"\"\n",
    "        self.img_pattern = img_pattern\n",
    "        self.K_orig = self.intrinsic_orig = intrinsic.copy()\n",
    "        self.output_dir = output_dir\n",
    "        self.downscale = downscale\n",
    "        self.rescale_intrinsic()\n",
    "\n",
    "    def rescale_intrinsic(self):\n",
    "        \"\"\"\n",
    "        if we downscale the image, the intrinsic matrix\n",
    "        also needs to be changed.\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        # scale focal length and principal points wrt image resizeing\n",
    "        if self.downscale > 1:\n",
    "            self.K = self.K_orig.copy()\n",
    "            self.K[0, 0] /= float(self.downscale)\n",
    "            self.K[1, 1] /= float(self.downscale)\n",
    "            self.K[0, 2] /= float(self.downscale)\n",
    "            self.K[1, 2] /= float(self.downscale)\n",
    "            self.intrinsic = self.K\n",
    "        else:\n",
    "            self.K = self.intrinsic = self.K_orig.copy()\n",
    "        elapsed = time.time() - start\n",
    "       \n",
    "              \n",
    "    def load_images(self):\n",
    "        \"\"\"\n",
    "        Loads a set of images to self.imgs list\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        self.img_paths = sorted(glob(self.img_pattern))\n",
    "        self.imgs = []\n",
    "        for idx, this_path in enumerate(self.img_paths):\n",
    "            try:\n",
    "                this_img = cv2.imread(this_path)\n",
    "                if self.downscale > 1:\n",
    "                    this_img = cv2.resize(this_img, (0, 0),\n",
    "                                          fx=1/float(self.downscale),\n",
    "                                          fy=1/float(self.downscale),\n",
    "                                          interpolation=cv2.INTER_LINEAR)\n",
    "            except Exception as e:\n",
    "                print(\"error loading img: %s\" % (this_path))\n",
    "            if this_img is not None:\n",
    "                self.imgs.append(this_img)\n",
    "                print(\"loaded img %d size=(%d,%d): %s\" %\n",
    "                      (idx, this_img.shape[0], this_img.shape[1], this_path))\n",
    "        #print(\"loaded %d images\" % (len(self.imgs)))\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "\n",
    "    def visualize_matches(self, img1, img2,\n",
    "                          kp1, kp2, good,\n",
    "                          mask=None, save_path=None):\n",
    "        start = time.time()\n",
    "        draw_params = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                           singlePointColor=None,\n",
    "                           flags=2)\n",
    "        if mask is not None:\n",
    "            if not isinstance(mask, list):\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "            else:\n",
    "                matchesMask = mask\n",
    "            draw_params['matchesMask'] = matchesMask\n",
    "        img_matches = cv2.drawMatches(\n",
    "            img1, kp1, img2, kp2, good, None, **draw_params)\n",
    "        cv2.imwrite(save_path, img_matches)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "\n",
    "    def drawlines(self, img1, img2, lines, pts1, pts2, line_num=None):\n",
    "        \"\"\"\n",
    "        Draw line connecting points in two images.\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        if img1.ndim == 2:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "            r, c = img1.shape\n",
    "        else:  # 3\n",
    "            r, c, _ = img1.shape\n",
    "        if line_num is not None:\n",
    "            draw_list = np.random.choice(\n",
    "                pts1.shape[0], line_num, replace=False)\n",
    "        else:\n",
    "            draw_list = np.arange(pts1.shape[0])\n",
    "        for idx, (r, pt1, pt2) in enumerate(zip(lines, pts1, pts2)):\n",
    "            if idx not in list(draw_list):\n",
    "                continue\n",
    "            color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "            x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "            x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "            img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 1)\n",
    "            img1 = cv2.circle(img1, tuple(pt1.ravel()), 5, color, -1)\n",
    "            img2 = cv2.circle(img2, tuple(pt2.ravel()), 5, color, -1)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return img1, img2\n",
    "\n",
    "    def visualize_epipolar_lines(self, img1, img2, p1, p2, E, save_path):\n",
    "        start = time.time()\n",
    "        # get fundamental matrix\n",
    "        F, mask_fdm = cv2.findFundamentalMat(p1, p2, cv2.RANSAC)\n",
    "        p1_selected = p1[mask_fdm.ravel() == 1]\n",
    "        p2_selected = p2[mask_fdm.ravel() == 1]\n",
    "\n",
    "        # draw lines\n",
    "        lines1 = cv2.computeCorrespondEpilines(\n",
    "            p2_selected.reshape(-1, 1, 2), 2, F).reshape(-1, 3)\n",
    "        img5, _ = self.drawlines(\n",
    "            img1, img2, lines1, p1_selected, p2_selected, 100)\n",
    "\n",
    "        lines2 = cv2.computeCorrespondEpilines(\n",
    "            p1_selected.reshape(-1, 1, 2), 1, F).reshape(-1, 3)\n",
    "        img3, _ = self.drawlines(\n",
    "            img2, img1, lines2, p2_selected, p1_selected, 100)\n",
    "        canvas = np.concatenate((img5, img3), axis=1)\n",
    "        cv2.imwrite(save_path, canvas)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "\n",
    "    def write_simple_obj(self, mesh_v, mesh_f, filepath, verbose=False):\n",
    "        \"\"\"\n",
    "        Saves 3d points which can be read in meshlab\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        with open(filepath, 'w') as fp:\n",
    "            for v in mesh_v:\n",
    "                fp.write('v %f %f %f\\n' % (v[0], v[1], v[2]))\n",
    "            if mesh_f is not None:\n",
    "                for f in mesh_f+1:  # Faces are 1-based, not 0-based in obj files\n",
    "                    fp.write('f %d %d %d\\n' % (f[0], f[1], f[2]))\n",
    "        if verbose:\n",
    "            print('mesh saved to: ', filepath)\n",
    "        elapsed = time.time() - start \n",
    "        \n",
    "        \n",
    "    def detect_and_match_feature(self, img1, img2):\n",
    "        start = time.time()\n",
    "        sift = cv2.xfeatures2d.SIFT_create() # Create SIFT object\n",
    "        kp1,des1 = sift.detectAndCompute(img1,None) # Detect keypoints and find descriptiors of first image\n",
    "        elapsed1 = time.time() - start\n",
    "        start1 = time.time()\n",
    "        kp2,des2 = sift.detectAndCompute(img2,None) # Detect keypoints and find descriptiors of second image\n",
    "        print(np.shape(des1))\n",
    "        print(np.shape(des2))\n",
    "        \n",
    "        \n",
    "        start2 = time.time()\n",
    "        start4 = time.time()\n",
    "        matches = KNNMatch(des1,des2,k=2)\n",
    "        \n",
    "        elapsed2 = time.time() - start4\n",
    "        print(\"Time for detect and match feature description {}\".format(elapsed2))\n",
    "        \n",
    "        matches_good = []\n",
    "        \n",
    "        start3 = time.time()\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.7 * n.distance: # Perform ratio test to select good feature matches. Here 0.7 is the threshold. Can change between 0.5 - 1\n",
    "                matches_good.append(m)\n",
    "        elapsed3 = time.time() - start3\n",
    "       \n",
    "        \n",
    "        p1 = np.float32([kp1[m.queryIdx].pt for m in matches_good]).reshape(-1,1,2) # Find those keypoints with descriptors that pass ratio test\n",
    "        p2 = np.float32([kp2[m.trainIdx].pt for m in matches_good]).reshape(-1,1,2) # Find those keypoints with descriptors that pass ratio test\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return p1, p2, matches_good, kp1, kp2\n",
    "\n",
    "    def compute_essential(self, p1, p2):\n",
    "        start = time.time()\n",
    "        E, mask = cv2.findEssentialMat(p1, p2, self.intrinsic) # Find essential matrix\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return E, mask\n",
    "\n",
    "    def compute_pose(self, p1, p2, E):\n",
    "        start = time.time()\n",
    "        retval, R, trans, mask = cv2.recoverPose(E, p1, p2, self.intrinsic)\n",
    "\n",
    "        #print(\" Rotation matrix is: \") # #print Rotation matrix. Rotation of second camera with respect to first\n",
    "        #print(R)\n",
    "        #print(\" Translation vector is: \") # #print Translation vector. Translation of second camera with respect to first\n",
    "        #print(trans)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return R, trans\n",
    "\n",
    "    def triangulate(self, p1, p2, R, trans, mask):\n",
    "        start = time.time()\n",
    "        matchesMask = mask.ravel().tolist() # Use mask to remove outliers\n",
    "        p1 = p1[np.asarray(matchesMask)==1,:,:]\n",
    "        p2 = p2[np.asarray(matchesMask)==1,:,:]\n",
    "\n",
    "        P1 = cv2.undistortPoints(p1, self.intrinsic,None) # Convert image coordinates to normalized coordinates for first image\n",
    "        P2 = cv2.undistortPoints(p2, self.intrinsic,None) # Convert image coordinates to normalized coordinates for second image\n",
    "\n",
    "        I = np.identity(3) # Rotation of first camera. Identity as origin is at first camera\n",
    "        z = np.zeros((3,1)) #  Translation of first camera. Zero as origin is at first camera\n",
    "\n",
    "        projMatr1 = np.concatenate((I,z),axis=1) # Calculate matrix of extrinsic parameters ([R t]) of first camera\n",
    "        #print(\"Projection matrix ([R t]) of first camera is: \") \n",
    "        #print(projMatr1)\n",
    "\n",
    "        projMatr2 = np.concatenate((R,trans),axis=1) # Calculate matrix of extrinsic parameters ([R t]) of second camera\n",
    "        #print(\"Projection matrix ([R t]) of second camera is: \")\n",
    "        #print(projMatr2)\n",
    "\n",
    "        #print(\"Camera matrix (K*[R t]) of first camera is: \") # Camera matrix (K*[R t]) of first camera\n",
    "        #print(self.intrinsic@projMatr1)\n",
    "\n",
    "        #print(\"Camera matrix (K*[R t]) of second camera is: \") # Camera matrix (K*[R t]) of second camera\n",
    "        #print(self.intrinsic@projMatr2)\n",
    "\n",
    "        points_4d_hom = cv2.triangulatePoints(projMatr1, projMatr2, P1, P2) # Homogeneous coordinates \n",
    "        points_4d = points_4d_hom / np.tile(points_4d_hom[-1,:],(4,1)) # divide by fourth coordinate to get 3D points\n",
    "        points_3d = points_4d[:3,:].T # Take first three coordinates (3D points)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return points_3d\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        self.load_images()\n",
    "\n",
    "        # pair processing\n",
    "\n",
    "        # step 1 and 2: detect and match feature\n",
    "        p1, p2, matches_good, kp1, kp2 = self.detect_and_match_feature(\n",
    "            self.imgs[1], self.imgs[2])\n",
    "\n",
    "        self.visualize_matches(\n",
    "           self.imgs[1], self.imgs[2], kp1, kp2, matches_good,\n",
    "          save_path=join(self.output_dir, 'sift_match_01_7.png'))\n",
    "\n",
    "        # step 3: compute essential matrix\n",
    "        E, mask = self.compute_essential(p1, p2)\n",
    "\n",
    "        self.visualize_matches(\n",
    "            self.imgs[1], self.imgs[2], kp1, kp2, matches_good, mask=mask,\n",
    "           save_path=join(self.output_dir, 'inlier_match_01_7.png'))\n",
    "\n",
    "        self.visualize_epipolar_lines(\n",
    "           self.imgs[1], self.imgs[2], p1, p2, E,\n",
    "           save_path=join(self.output_dir, 'epipolar_lines_01_7.png')) \n",
    "\n",
    "        # step 4: recover pose\n",
    "        R, trans = self.compute_pose(p1, p2, E)\n",
    "        # step 5: triangulation\n",
    "        point_3d = self.triangulate(p1, p2, R, trans, mask)\n",
    "        self.write_simple_obj(point_3d, None, filepath=join(\n",
    "            self.output_dir, 'output_01_7.obj')) # Output file to see point cloud in Meshlab. First two numbers (01) signify set of images used. Third number (7) gives threshold (here 0.7)\n",
    "\n",
    "def safe_mkdir(file_dir):\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.mkdir(file_dir)\n",
    "\n",
    "def intrinsic_reader(txt_file):\n",
    "    with open(txt_file) as f:\n",
    "        lines = f.readlines()\n",
    "    return np.array(\n",
    "        [l.strip().split(' ') for l in lines],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method which will load all input image files and output obj file paths \n",
    "\n",
    "Time taken for Descriptor matching will be printed below.\n",
    "\n",
    "Inorder to run of differnt image datasets, change the img_pattern and intrinsic path in the code below.\n",
    "For the data set accompanying this git repo, <br>\n",
    "For folder2: <br>\n",
    "img_pattern = '/data/folder2/*.jpg'* <br>\n",
    "intrinsic = intrinsic_reader('./data/folder2/intrinsics.txt') <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded img 0 size=(1024,1536): ./data/folder1\\rdimage.000.ppm\n",
      "loaded img 1 size=(1024,1536): ./data/folder1\\rdimage.001.ppm\n",
      "loaded img 2 size=(1024,1536): ./data/folder1\\rdimage.002.ppm\n",
      "(10275, 128)\n",
      "(10455, 128)\n",
      "Time for detect and match feature description 355.3411409854889\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    img_pattern = './data/folder1/*.ppm' \n",
    "    intrinsic = intrinsic_reader('./data/folder1/intrinsics.txt') # Retrieve intrinsic parameters\n",
    "    output_dir = './output' # Folder to save output results\n",
    "    safe_mkdir(output_dir)\n",
    "\n",
    "    sfm_solver = SFMSolver(img_pattern, intrinsic, output_dir, downscale=2)\n",
    "    sfm_solver.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
